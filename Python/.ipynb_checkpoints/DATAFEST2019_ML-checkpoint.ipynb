{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Michavillson/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Soreness</th>\n",
       "      <th>Desire</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>SleepHours</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>USG</th>\n",
       "      <th>perf_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.614124</td>\n",
       "      <td>3.517024</td>\n",
       "      <td>4.804540</td>\n",
       "      <td>4.089533</td>\n",
       "      <td>8.339849</td>\n",
       "      <td>3.453972</td>\n",
       "      <td>1.022636</td>\n",
       "      <td>0.757881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.865968</td>\n",
       "      <td>1.161254</td>\n",
       "      <td>1.014232</td>\n",
       "      <td>0.537300</td>\n",
       "      <td>0.909171</td>\n",
       "      <td>1.174524</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.428636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.014000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.017000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fatigue    Soreness      Desire  Irritability  SleepHours  \\\n",
       "count  793.000000  793.000000  793.000000    793.000000  793.000000   \n",
       "mean     3.614124    3.517024    4.804540      4.089533    8.339849   \n",
       "std      0.865968    1.161254    1.014232      0.537300    0.909171   \n",
       "min      1.000000    1.000000    1.000000      1.000000    5.750000   \n",
       "25%      3.000000    3.000000    4.000000      4.000000    8.000000   \n",
       "50%      4.000000    4.000000    5.000000      4.000000    8.500000   \n",
       "75%      4.000000    4.000000    5.000000      4.000000    9.000000   \n",
       "max      6.000000    7.000000    7.000000      6.000000   11.000000   \n",
       "\n",
       "       SleepQuality         USG  perf_class  \n",
       "count    793.000000  793.000000  793.000000  \n",
       "mean       3.453972    1.022636    0.757881  \n",
       "std        1.174524    0.029400    0.428636  \n",
       "min        1.000000    1.005000    0.000000  \n",
       "25%        3.000000    1.014000    1.000000  \n",
       "50%        4.000000    1.017000    1.000000  \n",
       "75%        4.000000    1.020000    1.000000  \n",
       "max        7.000000    1.180000    1.000000  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/training.csv\", sep=\",\")\n",
    "data = data.drop(data.columns[[6,7,8,10]], axis=1)\n",
    "data = data.dropna()\n",
    "\n",
    "# Sainty Check\n",
    "print(data.shape)\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(634, 7)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11234)\n",
    "# Split the dataset. \n",
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:,\"Fatigue\":\"USG\"], \n",
    "                                                    data[\"perf_class\"], \n",
    "                                                    test_size = 0.2)\n",
    "# Sainty Check\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Michavillson/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators = 30, learning_rate = 0.1, max_depth = 2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions) \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_parameters_df = pd.DataFrame(columns=[\"n_estimators\", \"max_depth\", \"learning_rate\", \n",
    "                                               \"reglambda\", \"missing\", \"objective\"])\n",
    "best_accuracy = 42.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10, 100)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exhaustive_search(X_train, X_test, y_train, y_test):\n",
    "    for n_estimators in range(0,100):\n",
    "        for max_depth in range(0,20):\n",
    "            for learning_rate in range(0,10,100):\n",
    "                learning_rate_float = learning_rate / 100.0\n",
    "                model = XGBClassifier(objective = \"multi:softprob\", missing = None, n_estimators = n_estimators, \n",
    "                                     max_depth = max_depth, learning_rate = learning_rate, reglambda=1)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = model.predict(X_test)\n",
    "                predictions = [round(value) for value in y_pred]\n",
    "                accuracy = accuracy_score(y_test, predictions) \n",
    "                if accuracy > best_accuracy:\n",
    "                    accuracy_parameters_df.append([n_estimators, max_depth, learning_rate, 1, None, \"multi:softprob\"])\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'value 0 for Parameter num_class should be greater equal to 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-8b543bc83a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexhaustive_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-226-6c6772ade39a>\u001b[0m in \u001b[0;36mexhaustive_search\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    770\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1294\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'value 0 for Parameter num_class should be greater equal to 1'"
     ]
    }
   ],
   "source": [
    "exhaustive_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [n_estimators, max_depth, learning_rate, reglambda, missing, objective]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_parameters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-148297692246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_SVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_SVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_SVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_SVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions_SVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred_SVM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "model_SVM = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "model_SVM.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SVM = model_SVM.predict(X_test)\n",
    "predictions_SVM = [round(value) for value in y_pred_SVM]\n",
    "\n",
    "accuracy_SVM = accuracy_score(y_test, predictions_SVM) \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_SVM * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     K  CV_Scores\n",
      "0    1   0.634083\n",
      "1    2   0.559955\n",
      "2    3   0.667229\n",
      "3    4   0.612048\n",
      "4    5   0.719260\n",
      "5    6   0.673541\n",
      "6    7   0.727147\n",
      "7    8   0.711386\n",
      "8    9   0.738183\n",
      "9   10   0.722410\n",
      "10  11   0.731871\n",
      "11  12   0.722397\n",
      "12  13   0.742907\n",
      "13  14   0.736595\n",
      "14  15   0.742920\n",
      "15  16   0.735033\n",
      "16  17   0.744482\n",
      "17  18   0.738183\n",
      "18  19   0.747632\n"
     ]
    }
   ],
   "source": [
    "# K Neariest Neighbors\n",
    "# K value list and cv scores list initialization. \n",
    "k_list = list(range(1,20))\n",
    "cv_scores = []\n",
    "\n",
    "# Fit the knn model and calculate the cv scores. \n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv = 5, scoring = \"accuracy\")\n",
    "    cv_scores.append(scores.mean()) \n",
    "    \n",
    "k_df = pd.DataFrame({\"K\":k_list, \"CV_Scores\":cv_scores})\n",
    "print(k_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7861635220125787\n"
     ]
    }
   ],
   "source": [
    "# Initialize the knn model with k = 13 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "# Fit the model with trainning data. \n",
    "knn.fit(X_train, y_train)\n",
    "# Predicting the test data. \n",
    "pred = knn.predict(X_test)\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy: \", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2d59b6a0>]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_list = list(range(1,20))\n",
    "fit_scores = []\n",
    "\n",
    "# Just curious about how each k performs on test data. \n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    fit_scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(k_list, fit_scores, \"o\", color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model):\n",
    "    pred_res = model.predict(X_test)\n",
    "    prediction = [round(value) for value in pred_res]\n",
    "    accuracy = accuracy_score(y_test, prediction) \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987421383647799\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model_logis = LogisticRegression(solver=\"newton-cg\").fit(X_train, y_train)\n",
    "accuracy_logis = pred(model_logis)\n",
    "print(accuracy_logis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6792452830188679\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree: \n",
    "model_decTree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "accuracy_decTree = pred(model_decTree)\n",
    "print(accuracy_decTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.55%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "model_rf = RandomForestClassifier(n_estimators=700,\n",
    "                                  bootstrap=False,\n",
    "                                  max_depth=18,\n",
    "                                  min_impurity_decrease=0,\n",
    "                                  min_samples_leaf=2)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "predictions_rf = [round(value) for value in y_pred_rf]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, predictions_rf)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_rf * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
